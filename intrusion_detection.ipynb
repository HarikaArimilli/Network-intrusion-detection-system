{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datacols = [\"duration\",\"protocol_type\",\"service\",\"flag\",\"src_bytes\",\n",
    "    \"dst_bytes\",\"land\",\"wrong_fragment\",\"urgent\",\"hot\",\"num_failed_logins\",\n",
    "    \"logged_in\",\"num_compromised\",\"root_shell\",\"su_attempted\",\"num_root\",\n",
    "    \"num_file_creations\",\"num_shells\",\"num_access_files\",\"num_outbound_cmds\",\n",
    "    \"is_host_login\",\"is_guest_login\",\"count\",\"srv_count\",\"serror_rate\",\n",
    "    \"srv_serror_rate\",\"rerror_rate\",\"srv_rerror_rate\",\"same_srv_rate\",\n",
    "    \"diff_srv_rate\",\"srv_diff_host_rate\",\"dst_host_count\",\"dst_host_srv_count\",\n",
    "    \"dst_host_same_srv_rate\",\"dst_host_diff_srv_rate\",\"dst_host_same_src_port_rate\",\n",
    "    \"dst_host_srv_diff_host_rate\",\"dst_host_serror_rate\",\"dst_host_srv_serror_rate\",\n",
    "    \"dst_host_rerror_rate\",\"dst_host_srv_rerror_rate\",\"attack\", \"last_flag\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_table(\"KDDTrain+.txt\",sep=',',names=datacols)\n",
    "df_test=pd.read_table(\"KDDTest+.txt\",sep=',',names=datacols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['attack'] = df_train['attack'].replace(['normal'],'Normal')\n",
    "df_train['attack']=df_train['attack'].replace(['neptune','satan','ipsweep','portsweep','smurf','nmap','back','teardrop','warezclient','pod','guess_passwd','buffer_overflow','warezmaster','land','imap','rootkit','loadmodule','ftp_write','multihop','phf','perl','spy'],'Attack')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping attacks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['attack'] = df_test['attack'].replace(['normal'],'Normal')\n",
    "df_test['attack']=df_test['attack'].replace(['neptune','mscan','apache2','processtable','snmpguess','saint','mailbomb',\n",
    "                                             'snmpgetattack','httptunnel','named','ps','sendmail','xterm','xlock','xsnoop','sqlattack','worm','udpstorm',\n",
    "                                             'satan','ipsweep','portsweep','smurf','nmap','back','teardrop','warezclient','pod','guess_passwd','buffer_overflow','warezmaster','land','imap','rootkit','loadmodule','ftp_write','multihop','phf','perl','spy'],'Attack')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>attack</th>\n",
       "      <th>last_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Attack</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>REJ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>Attack</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>12983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>icmp</td>\n",
       "      <td>eco_i</td>\n",
       "      <td>SF</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Attack</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tcp</td>\n",
       "      <td>telnet</td>\n",
       "      <td>RSTO</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.71</td>\n",
       "      <td>Attack</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp   private   REJ          0          0     0   \n",
       "1         0           tcp   private   REJ          0          0     0   \n",
       "2         2           tcp  ftp_data    SF      12983          0     0   \n",
       "3         0          icmp     eco_i    SF         20          0     0   \n",
       "4         1           tcp    telnet  RSTO          0         15     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.04   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.61   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    0.31   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.06                         0.00   \n",
       "1                    0.06                         0.00   \n",
       "2                    0.04                         0.61   \n",
       "3                    0.00                         1.00   \n",
       "4                    0.17                         0.03   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                   0.0   \n",
       "1                         0.00                   0.0   \n",
       "2                         0.02                   0.0   \n",
       "3                         0.28                   0.0   \n",
       "4                         0.02                   0.0   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                       0.0                  1.00                      1.00   \n",
       "1                       0.0                  1.00                      1.00   \n",
       "2                       0.0                  0.00                      0.00   \n",
       "3                       0.0                  0.00                      0.00   \n",
       "4                       0.0                  0.83                      0.71   \n",
       "\n",
       "   attack  last_flag  \n",
       "0  Attack         21  \n",
       "1  Attack         21  \n",
       "2  Normal         21  \n",
       "3  Attack         15  \n",
       "4  Attack         11  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>attack</th>\n",
       "      <th>last_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>ftp_data</td>\n",
       "      <td>SF</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>udp</td>\n",
       "      <td>other</td>\n",
       "      <td>SF</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>private</td>\n",
       "      <td>S0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Attack</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>tcp</td>\n",
       "      <td>http</td>\n",
       "      <td>SF</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>Normal</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration protocol_type   service flag  src_bytes  dst_bytes  land  \\\n",
       "0         0           tcp  ftp_data   SF        491          0     0   \n",
       "1         0           udp     other   SF        146          0     0   \n",
       "2         0           tcp   private   S0          0          0     0   \n",
       "3         0           tcp      http   SF        232       8153     0   \n",
       "4         0           tcp      http   SF        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_same_srv_rate  \\\n",
       "0               0       0    0  ...                    0.17   \n",
       "1               0       0    0  ...                    0.00   \n",
       "2               0       0    0  ...                    0.10   \n",
       "3               0       0    0  ...                    1.00   \n",
       "4               0       0    0  ...                    1.00   \n",
       "\n",
       "   dst_host_diff_srv_rate  dst_host_same_src_port_rate  \\\n",
       "0                    0.03                         0.17   \n",
       "1                    0.60                         0.88   \n",
       "2                    0.05                         0.00   \n",
       "3                    0.00                         0.03   \n",
       "4                    0.00                         0.00   \n",
       "\n",
       "   dst_host_srv_diff_host_rate  dst_host_serror_rate  \\\n",
       "0                         0.00                  0.00   \n",
       "1                         0.00                  0.00   \n",
       "2                         0.00                  1.00   \n",
       "3                         0.04                  0.03   \n",
       "4                         0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_serror_rate  dst_host_rerror_rate  dst_host_srv_rerror_rate  \\\n",
       "0                      0.00                  0.05                      0.00   \n",
       "1                      0.00                  0.00                      0.00   \n",
       "2                      1.00                  0.00                      0.00   \n",
       "3                      0.01                  0.00                      0.01   \n",
       "4                      0.00                  0.00                      0.00   \n",
       "\n",
       "   attack  last_flag  \n",
       "0  Normal         20  \n",
       "1  Normal         15  \n",
       "2  Attack         19  \n",
       "3  Normal         21  \n",
       "4  Normal         21  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>last_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>125973.00000</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>1.259730e+05</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "      <td>125973.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>287.14465</td>\n",
       "      <td>4.556674e+04</td>\n",
       "      <td>1.977911e+04</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.022687</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.204409</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.395736</td>\n",
       "      <td>0.279250</td>\n",
       "      <td>...</td>\n",
       "      <td>115.653005</td>\n",
       "      <td>0.521242</td>\n",
       "      <td>0.082951</td>\n",
       "      <td>0.148379</td>\n",
       "      <td>0.032542</td>\n",
       "      <td>0.284452</td>\n",
       "      <td>0.278485</td>\n",
       "      <td>0.118832</td>\n",
       "      <td>0.120240</td>\n",
       "      <td>19.504060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2604.51531</td>\n",
       "      <td>5.870331e+06</td>\n",
       "      <td>4.021269e+06</td>\n",
       "      <td>0.014086</td>\n",
       "      <td>0.253530</td>\n",
       "      <td>0.014366</td>\n",
       "      <td>2.149968</td>\n",
       "      <td>0.045239</td>\n",
       "      <td>0.489010</td>\n",
       "      <td>23.942042</td>\n",
       "      <td>...</td>\n",
       "      <td>110.702741</td>\n",
       "      <td>0.448949</td>\n",
       "      <td>0.188922</td>\n",
       "      <td>0.308997</td>\n",
       "      <td>0.112564</td>\n",
       "      <td>0.444784</td>\n",
       "      <td>0.445669</td>\n",
       "      <td>0.306557</td>\n",
       "      <td>0.319459</td>\n",
       "      <td>2.291503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>4.400000e+01</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0.510000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>2.760000e+02</td>\n",
       "      <td>5.160000e+02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>42908.00000</td>\n",
       "      <td>1.379964e+09</td>\n",
       "      <td>1.309937e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7479.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           duration     src_bytes     dst_bytes           land  \\\n",
       "count  125973.00000  1.259730e+05  1.259730e+05  125973.000000   \n",
       "mean      287.14465  4.556674e+04  1.977911e+04       0.000198   \n",
       "std      2604.51531  5.870331e+06  4.021269e+06       0.014086   \n",
       "min         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "25%         0.00000  0.000000e+00  0.000000e+00       0.000000   \n",
       "50%         0.00000  4.400000e+01  0.000000e+00       0.000000   \n",
       "75%         0.00000  2.760000e+02  5.160000e+02       0.000000   \n",
       "max     42908.00000  1.379964e+09  1.309937e+09       1.000000   \n",
       "\n",
       "       wrong_fragment         urgent            hot  num_failed_logins  \\\n",
       "count   125973.000000  125973.000000  125973.000000      125973.000000   \n",
       "mean         0.022687       0.000111       0.204409           0.001222   \n",
       "std          0.253530       0.014366       2.149968           0.045239   \n",
       "min          0.000000       0.000000       0.000000           0.000000   \n",
       "25%          0.000000       0.000000       0.000000           0.000000   \n",
       "50%          0.000000       0.000000       0.000000           0.000000   \n",
       "75%          0.000000       0.000000       0.000000           0.000000   \n",
       "max          3.000000       3.000000      77.000000           5.000000   \n",
       "\n",
       "           logged_in  num_compromised  ...  dst_host_srv_count  \\\n",
       "count  125973.000000    125973.000000  ...       125973.000000   \n",
       "mean        0.395736         0.279250  ...          115.653005   \n",
       "std         0.489010        23.942042  ...          110.702741   \n",
       "min         0.000000         0.000000  ...            0.000000   \n",
       "25%         0.000000         0.000000  ...           10.000000   \n",
       "50%         0.000000         0.000000  ...           63.000000   \n",
       "75%         1.000000         0.000000  ...          255.000000   \n",
       "max         1.000000      7479.000000  ...          255.000000   \n",
       "\n",
       "       dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "count           125973.000000           125973.000000   \n",
       "mean                 0.521242                0.082951   \n",
       "std                  0.448949                0.188922   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.050000                0.000000   \n",
       "50%                  0.510000                0.020000   \n",
       "75%                  1.000000                0.070000   \n",
       "max                  1.000000                1.000000   \n",
       "\n",
       "       dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "count                125973.000000                125973.000000   \n",
       "mean                      0.148379                     0.032542   \n",
       "std                       0.308997                     0.112564   \n",
       "min                       0.000000                     0.000000   \n",
       "25%                       0.000000                     0.000000   \n",
       "50%                       0.000000                     0.000000   \n",
       "75%                       0.060000                     0.020000   \n",
       "max                       1.000000                     1.000000   \n",
       "\n",
       "       dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "count         125973.000000             125973.000000         125973.000000   \n",
       "mean               0.284452                  0.278485              0.118832   \n",
       "std                0.444784                  0.445669              0.306557   \n",
       "min                0.000000                  0.000000              0.000000   \n",
       "25%                0.000000                  0.000000              0.000000   \n",
       "50%                0.000000                  0.000000              0.000000   \n",
       "75%                1.000000                  1.000000              0.000000   \n",
       "max                1.000000                  1.000000              1.000000   \n",
       "\n",
       "       dst_host_srv_rerror_rate      last_flag  \n",
       "count             125973.000000  125973.000000  \n",
       "mean                   0.120240      19.504060  \n",
       "std                    0.319459       2.291503  \n",
       "min                    0.000000       0.000000  \n",
       "25%                    0.000000      18.000000  \n",
       "50%                    0.000000      20.000000  \n",
       "75%                    0.000000      21.000000  \n",
       "max                    1.000000      21.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of attak and normal classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attack</th>\n",
       "      <th>frequency_percent_train</th>\n",
       "      <th>attack</th>\n",
       "      <th>frequency_percent_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Normal</th>\n",
       "      <td>67343</td>\n",
       "      <td>53.46</td>\n",
       "      <td>9711</td>\n",
       "      <td>43.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Attack</th>\n",
       "      <td>58630</td>\n",
       "      <td>46.54</td>\n",
       "      <td>12833</td>\n",
       "      <td>56.92</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        attack  frequency_percent_train  attack  frequency_percent_test\n",
       "Normal   67343                    53.46    9711                   43.08\n",
       "Attack   58630                    46.54   12833                   56.92"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_class_freq_train = df_train[['attack']].apply(lambda x: x.value_counts())\n",
    "attack_class_freq_test = df_test[['attack']].apply(lambda x: x.value_counts())\n",
    "attack_class_freq_train['frequency_percent_train'] = round((100 * attack_class_freq_train / attack_class_freq_train.sum()),2)\n",
    "attack_class_freq_test['frequency_percent_test'] = round((100 * attack_class_freq_test / attack_class_freq_test.sum()),2)\n",
    "\n",
    "attack_class_dist = pd.concat([attack_class_freq_train,attack_class_freq_test], axis=1) \n",
    "attack_class_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot = attack_class_dist[['frequency_percent_train', 'frequency_percent_test']].plot(kind=\"bar\");\n",
    "plot.set_title(\"Attack Class Distribution\", fontsize=20);\n",
    "plot.grid(color='lightgray', alpha=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data PreProcessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "cols=df_train.select_dtypes(include=['float64','int64']).columns\n",
    "sc_train = sc.fit_transform(df_train.select_dtypes(include=['float64','int64']))\n",
    "sc_test = sc.fit_transform(df_test.select_dtypes(include=['float64','int64']))\n",
    "\n",
    "# turn the result back to a dataframe\n",
    "sc_traindf = pd.DataFrame(sc_train, columns = cols)\n",
    "sc_testdf = pd.DataFrame(sc_test, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>num_failed_logins</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>num_compromised</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "      <th>last_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007679</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>-0.782367</td>\n",
       "      <td>-0.280282</td>\n",
       "      <td>0.069972</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.224532</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>0.216426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.035688</td>\n",
       "      <td>-1.161030</td>\n",
       "      <td>2.736852</td>\n",
       "      <td>2.367737</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>-1.965556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.809857</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.174417</td>\n",
       "      <td>-0.480197</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>-0.219970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007723</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>-0.439078</td>\n",
       "      <td>-0.383108</td>\n",
       "      <td>0.066252</td>\n",
       "      <td>-0.572083</td>\n",
       "      <td>-0.602433</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.345084</td>\n",
       "      <td>0.652823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007728</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>-0.439078</td>\n",
       "      <td>-0.480197</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>0.652823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.121485</td>\n",
       "      <td>-0.480197</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>0.216426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>-0.107178</td>\n",
       "      <td>-0.007744</td>\n",
       "      <td>-0.004883</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>1.159389</td>\n",
       "      <td>0.977304</td>\n",
       "      <td>-0.386146</td>\n",
       "      <td>-0.447834</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>0.652823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007382</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.773724</td>\n",
       "      <td>-0.893738</td>\n",
       "      <td>-0.121485</td>\n",
       "      <td>-0.480197</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>0.979238</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.355014</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>-0.656367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>-0.809262</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.972455</td>\n",
       "      <td>-1.094207</td>\n",
       "      <td>-0.174417</td>\n",
       "      <td>-0.480197</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>1.608759</td>\n",
       "      <td>1.618955</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>0.216426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>-0.110249</td>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.014089</td>\n",
       "      <td>-0.089486</td>\n",
       "      <td>-0.007736</td>\n",
       "      <td>-0.095076</td>\n",
       "      <td>-0.027023</td>\n",
       "      <td>1.235694</td>\n",
       "      <td>-0.011664</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.349162</td>\n",
       "      <td>-0.492801</td>\n",
       "      <td>-0.280282</td>\n",
       "      <td>0.490690</td>\n",
       "      <td>-0.289103</td>\n",
       "      <td>-0.639532</td>\n",
       "      <td>-0.624871</td>\n",
       "      <td>-0.387635</td>\n",
       "      <td>-0.376387</td>\n",
       "      <td>0.652823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        duration  src_bytes  dst_bytes      land  wrong_fragment    urgent  \\\n",
       "0      -0.110249  -0.007679  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "1      -0.110249  -0.007737  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "2      -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "3      -0.110249  -0.007723  -0.002891 -0.014089       -0.089486 -0.007736   \n",
       "4      -0.110249  -0.007728  -0.004814 -0.014089       -0.089486 -0.007736   \n",
       "...          ...        ...        ...       ...             ...       ...   \n",
       "125968 -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "125969 -0.107178  -0.007744  -0.004883 -0.014089       -0.089486 -0.007736   \n",
       "125970 -0.110249  -0.007382  -0.004823 -0.014089       -0.089486 -0.007736   \n",
       "125971 -0.110249  -0.007762  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "125972 -0.110249  -0.007737  -0.004919 -0.014089       -0.089486 -0.007736   \n",
       "\n",
       "             hot  num_failed_logins  logged_in  num_compromised  ...  \\\n",
       "0      -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "1      -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "2      -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "3      -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "4      -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "...          ...                ...        ...              ...  ...   \n",
       "125968 -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "125969 -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "125970 -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "125971 -0.095076          -0.027023  -0.809262        -0.011664  ...   \n",
       "125972 -0.095076          -0.027023   1.235694        -0.011664  ...   \n",
       "\n",
       "        dst_host_srv_count  dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                -0.818890               -0.782367               -0.280282   \n",
       "1                -1.035688               -1.161030                2.736852   \n",
       "2                -0.809857               -0.938287               -0.174417   \n",
       "3                 1.258754                1.066401               -0.439078   \n",
       "4                 1.258754                1.066401               -0.439078   \n",
       "...                    ...                     ...                     ...   \n",
       "125968           -0.818890               -0.938287               -0.121485   \n",
       "125969            1.159389                0.977304               -0.386146   \n",
       "125970           -0.773724               -0.893738               -0.121485   \n",
       "125971           -0.972455               -1.094207               -0.174417   \n",
       "125972           -0.349162               -0.492801               -0.280282   \n",
       "\n",
       "        dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                          0.069972                    -0.289103   \n",
       "1                          2.367737                    -0.289103   \n",
       "2                         -0.480197                    -0.289103   \n",
       "3                         -0.383108                     0.066252   \n",
       "4                         -0.480197                    -0.289103   \n",
       "...                             ...                          ...   \n",
       "125968                    -0.480197                    -0.289103   \n",
       "125969                    -0.447834                    -0.289103   \n",
       "125970                    -0.480197                    -0.289103   \n",
       "125971                    -0.480197                    -0.289103   \n",
       "125972                     0.490690                    -0.289103   \n",
       "\n",
       "        dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  -0.639532                 -0.624871             -0.224532   \n",
       "1                  -0.639532                 -0.624871             -0.387635   \n",
       "2                   1.608759                  1.618955             -0.387635   \n",
       "3                  -0.572083                 -0.602433             -0.387635   \n",
       "4                  -0.639532                 -0.624871             -0.387635   \n",
       "...                      ...                       ...                   ...   \n",
       "125968              1.608759                  1.618955             -0.387635   \n",
       "125969             -0.639532                 -0.624871             -0.387635   \n",
       "125970              0.979238                 -0.624871             -0.355014   \n",
       "125971              1.608759                  1.618955             -0.387635   \n",
       "125972             -0.639532                 -0.624871             -0.387635   \n",
       "\n",
       "        dst_host_srv_rerror_rate  last_flag  \n",
       "0                      -0.376387   0.216426  \n",
       "1                      -0.376387  -1.965556  \n",
       "2                      -0.376387  -0.219970  \n",
       "3                      -0.345084   0.652823  \n",
       "4                      -0.376387   0.652823  \n",
       "...                          ...        ...  \n",
       "125968                 -0.376387   0.216426  \n",
       "125969                 -0.376387   0.652823  \n",
       "125970                 -0.376387  -0.656367  \n",
       "125971                 -0.376387   0.216426  \n",
       "125972                 -0.376387   0.652823  \n",
       "\n",
       "[125973 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc_traindf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "en=LabelEncoder()\n",
    "cattrain = df_train.select_dtypes(include=['object']).copy()\n",
    "cattest = df_test.select_dtypes(include=['object']).copy()\n",
    "\n",
    "# encode the categorical attributes\n",
    "traincat = cattrain.apply(en.fit_transform)\n",
    "testcat = cattest.apply(en.fit_transform)\n",
    "\n",
    "# separate target column from encoded data \n",
    "enctrain = traincat.drop(['attack'], axis=1)\n",
    "enctest = testcat.drop(['attack'], axis=1)\n",
    "\n",
    "cat_Ytrain = traincat[['attack']].copy()\n",
    "cat_Ytest = testcat[['attack']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=pd.concat([sc_traindf,enctrain],axis=1)\n",
    "X_test=pd.concat([sc_testdf,enctest],axis=1)\n",
    "X_trainarr= np.concatenate((sc_train, enctrain.values), axis=1)\n",
    "refcol=pd.concat([sc_traindf,enctrain],axis=1).columns\n",
    "c, r = cat_Ytrain.values.shape\n",
    "y = cat_Ytrain.values.reshape(c,)\n",
    "c, r = cat_Ytest.values.shape\n",
    "y_test = cat_Ytest.values.reshape(c,)\n",
    "Y_train=cat_Ytrain\n",
    "Y_test=cat_Ytest\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False,  True,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False,  True,  True,\n",
       "       False, False,  True,  True, False, False, False, False, False,\n",
       "       False, False,  True,  True, False,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import itertools\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# fit random forest classifier on the training set\n",
    "\n",
    "# create the RFE model and select 10 attributes\n",
    "rfe = RFE(rfc, n_features_to_select=10,step=1)\n",
    "rfe = rfe.fit(X_trainarr, y)\n",
    "rfe.support_\n",
    "# summarize the selection of the attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['duration', 'src_bytes', 'dst_bytes', 'land', 'wrong_fragment',\n",
       "       'urgent', 'hot', 'num_failed_logins', 'logged_in', 'num_compromised',\n",
       "       'root_shell', 'su_attempted', 'num_root', 'num_file_creations',\n",
       "       'num_shells', 'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
       "       'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
       "       'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
       "       'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
       "       'dst_host_srv_count', 'dst_host_same_srv_rate',\n",
       "       'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
       "       'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
       "       'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
       "       'dst_host_srv_rerror_rate', 'last_flag', 'protocol_type', 'service',\n",
       "       'flag'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refcol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "selected features are src_bytes,dst_bytes,count,same_srv_rate,diff_srv_rate,dst_host_srv_count,dst_host_same_srv_count,last_flag,protocol_type,flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_train=X_train[['src_bytes','dst_bytes','count','same_srv_rate','diff_srv_rate','dst_host_srv_count','dst_host_same_srv_rate','last_flag','protocol_type','flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>count</th>\n",
       "      <th>same_srv_rate</th>\n",
       "      <th>diff_srv_rate</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>last_flag</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.007679</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>-0.349683</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>-0.782367</td>\n",
       "      <td>0.216426</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.620982</td>\n",
       "      <td>-1.321428</td>\n",
       "      <td>0.482201</td>\n",
       "      <td>-1.035688</td>\n",
       "      <td>-1.161030</td>\n",
       "      <td>-1.965556</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.339648</td>\n",
       "      <td>-1.389669</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>-0.809857</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>-0.219970</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.007723</td>\n",
       "      <td>-0.002891</td>\n",
       "      <td>-0.690846</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>-0.349683</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>0.652823</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007728</td>\n",
       "      <td>-0.004814</td>\n",
       "      <td>-0.472521</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>-0.349683</td>\n",
       "      <td>1.258754</td>\n",
       "      <td>1.066401</td>\n",
       "      <td>0.652823</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125968</th>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.872361</td>\n",
       "      <td>-1.184947</td>\n",
       "      <td>-0.016930</td>\n",
       "      <td>-0.818890</td>\n",
       "      <td>-0.938287</td>\n",
       "      <td>0.216426</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125969</th>\n",
       "      <td>-0.007744</td>\n",
       "      <td>-0.004883</td>\n",
       "      <td>-0.717045</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>-0.349683</td>\n",
       "      <td>1.159389</td>\n",
       "      <td>0.977304</td>\n",
       "      <td>0.652823</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125970</th>\n",
       "      <td>-0.007382</td>\n",
       "      <td>-0.004823</td>\n",
       "      <td>-0.725778</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>-0.349683</td>\n",
       "      <td>-0.773724</td>\n",
       "      <td>-0.893738</td>\n",
       "      <td>-0.656367</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125971</th>\n",
       "      <td>-0.007762</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.523041</td>\n",
       "      <td>-1.366922</td>\n",
       "      <td>-0.072389</td>\n",
       "      <td>-0.972455</td>\n",
       "      <td>-1.094207</td>\n",
       "      <td>0.216426</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125972</th>\n",
       "      <td>-0.007737</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.725778</td>\n",
       "      <td>0.771283</td>\n",
       "      <td>-0.349683</td>\n",
       "      <td>-0.349162</td>\n",
       "      <td>-0.492801</td>\n",
       "      <td>0.652823</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125973 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        src_bytes  dst_bytes     count  same_srv_rate  diff_srv_rate  \\\n",
       "0       -0.007679  -0.004919 -0.717045       0.771283      -0.349683   \n",
       "1       -0.007737  -0.004919 -0.620982      -1.321428       0.482201   \n",
       "2       -0.007762  -0.004919  0.339648      -1.389669       0.038529   \n",
       "3       -0.007723  -0.002891 -0.690846       0.771283      -0.349683   \n",
       "4       -0.007728  -0.004814 -0.472521       0.771283      -0.349683   \n",
       "...           ...        ...       ...            ...            ...   \n",
       "125968  -0.007762  -0.004919  0.872361      -1.184947      -0.016930   \n",
       "125969  -0.007744  -0.004883 -0.717045       0.771283      -0.349683   \n",
       "125970  -0.007382  -0.004823 -0.725778       0.771283      -0.349683   \n",
       "125971  -0.007762  -0.004919  0.523041      -1.366922      -0.072389   \n",
       "125972  -0.007737  -0.004919 -0.725778       0.771283      -0.349683   \n",
       "\n",
       "        dst_host_srv_count  dst_host_same_srv_rate  last_flag  protocol_type  \\\n",
       "0                -0.818890               -0.782367   0.216426              1   \n",
       "1                -1.035688               -1.161030  -1.965556              2   \n",
       "2                -0.809857               -0.938287  -0.219970              1   \n",
       "3                 1.258754                1.066401   0.652823              1   \n",
       "4                 1.258754                1.066401   0.652823              1   \n",
       "...                    ...                     ...        ...            ...   \n",
       "125968           -0.818890               -0.938287   0.216426              1   \n",
       "125969            1.159389                0.977304   0.652823              2   \n",
       "125970           -0.773724               -0.893738  -0.656367              1   \n",
       "125971           -0.972455               -1.094207   0.216426              1   \n",
       "125972           -0.349162               -0.492801   0.652823              1   \n",
       "\n",
       "        flag  \n",
       "0          9  \n",
       "1          9  \n",
       "2          5  \n",
       "3          9  \n",
       "4          9  \n",
       "...      ...  \n",
       "125968     5  \n",
       "125969     9  \n",
       "125970     9  \n",
       "125971     5  \n",
       "125972     9  \n",
       "\n",
       "[125973 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final_test=X_test[['src_bytes','dst_bytes','count','same_srv_rate','diff_srv_rate','dst_host_srv_count','dst_host_same_srv_rate','last_flag','protocol_type','flag']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22544, 10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_final_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=traincat['attack']\n",
    "y_test=testcat['attack']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.22017985\n",
      "Iteration 2, loss = 0.12077266\n",
      "Iteration 3, loss = 0.10595004\n",
      "Iteration 4, loss = 0.09381350\n",
      "Iteration 5, loss = 0.08231161\n",
      "Iteration 6, loss = 0.07272505\n",
      "Iteration 7, loss = 0.06514838\n",
      "Iteration 8, loss = 0.06010831\n",
      "Iteration 9, loss = 0.05606247\n",
      "Iteration 10, loss = 0.05329611\n",
      "Iteration 11, loss = 0.05134068\n",
      "Iteration 12, loss = 0.04954901\n",
      "Iteration 13, loss = 0.04795605\n",
      "Iteration 14, loss = 0.04672416\n",
      "Iteration 15, loss = 0.04572834\n",
      "Iteration 16, loss = 0.04488793\n",
      "Iteration 17, loss = 0.04408527\n",
      "Iteration 18, loss = 0.04328330\n",
      "Iteration 19, loss = 0.04271040\n",
      "Iteration 20, loss = 0.04208268\n",
      "Iteration 21, loss = 0.04170640\n",
      "Iteration 22, loss = 0.04116751\n",
      "Iteration 23, loss = 0.04086914\n",
      "Iteration 24, loss = 0.04035221\n",
      "Iteration 25, loss = 0.04001089\n",
      "Iteration 26, loss = 0.03962644\n",
      "Iteration 27, loss = 0.03927252\n",
      "Iteration 28, loss = 0.03893335\n",
      "Iteration 29, loss = 0.03862043\n",
      "Iteration 30, loss = 0.03831458\n",
      "Iteration 31, loss = 0.03797071\n",
      "Iteration 32, loss = 0.03765297\n",
      "Iteration 33, loss = 0.03742723\n",
      "Iteration 34, loss = 0.03716821\n",
      "Iteration 35, loss = 0.03674443\n",
      "Iteration 36, loss = 0.03654196\n",
      "Iteration 37, loss = 0.03632013\n",
      "Iteration 38, loss = 0.03618330\n",
      "Iteration 39, loss = 0.03591951\n",
      "Iteration 40, loss = 0.03577407\n",
      "Iteration 41, loss = 0.03561482\n",
      "Iteration 42, loss = 0.03534472\n",
      "Iteration 43, loss = 0.03505791\n",
      "Iteration 44, loss = 0.03476274\n",
      "Iteration 45, loss = 0.03463419\n",
      "Iteration 46, loss = 0.03451397\n",
      "Iteration 47, loss = 0.03419892\n",
      "Iteration 48, loss = 0.03420136\n",
      "Iteration 49, loss = 0.03390463\n",
      "Iteration 50, loss = 0.03365367\n",
      "Iteration 51, loss = 0.03359629\n",
      "Iteration 52, loss = 0.03334049\n",
      "Iteration 53, loss = 0.03317173\n",
      "Iteration 54, loss = 0.03293694\n",
      "Iteration 55, loss = 0.03298806\n",
      "Iteration 56, loss = 0.03281916\n",
      "Iteration 57, loss = 0.03247372\n",
      "Iteration 58, loss = 0.03228026\n",
      "Iteration 59, loss = 0.03246932\n",
      "Iteration 60, loss = 0.03208374\n",
      "Iteration 61, loss = 0.03194978\n",
      "Iteration 62, loss = 0.03186405\n",
      "Iteration 63, loss = 0.03160764\n",
      "Iteration 64, loss = 0.03139246\n",
      "Iteration 65, loss = 0.03122531\n",
      "Iteration 66, loss = 0.03124906\n",
      "Iteration 67, loss = 0.03104367\n",
      "Iteration 68, loss = 0.03081885\n",
      "Iteration 69, loss = 0.03083839\n",
      "Iteration 70, loss = 0.03069941\n",
      "Iteration 71, loss = 0.03066679\n",
      "Iteration 72, loss = 0.03037113\n",
      "Iteration 73, loss = 0.03019594\n",
      "Iteration 74, loss = 0.03013781\n",
      "Iteration 75, loss = 0.03015346\n",
      "Iteration 76, loss = 0.02988893\n",
      "Iteration 77, loss = 0.02996968\n",
      "Iteration 78, loss = 0.02969477\n",
      "Iteration 79, loss = 0.02943798\n",
      "Iteration 80, loss = 0.02931468\n",
      "Iteration 81, loss = 0.02927884\n",
      "Iteration 82, loss = 0.02922777\n",
      "Iteration 83, loss = 0.02896938\n",
      "Iteration 84, loss = 0.02884321\n",
      "Iteration 85, loss = 0.02888555\n",
      "Iteration 86, loss = 0.02866535\n",
      "Iteration 87, loss = 0.02856524\n",
      "Iteration 88, loss = 0.02841046\n",
      "Iteration 89, loss = 0.02834245\n",
      "Iteration 90, loss = 0.02830841\n",
      "Iteration 91, loss = 0.02793079\n",
      "Iteration 92, loss = 0.02806811\n",
      "Iteration 93, loss = 0.02791510\n",
      "Iteration 94, loss = 0.02783519\n",
      "Iteration 95, loss = 0.02771212\n",
      "Iteration 96, loss = 0.02751914\n",
      "Iteration 97, loss = 0.02747633\n",
      "Iteration 98, loss = 0.02736198\n",
      "Iteration 99, loss = 0.02706289\n",
      "Iteration 100, loss = 0.02718127\n",
      "Iteration 101, loss = 0.02711104\n",
      "Iteration 102, loss = 0.02728027\n",
      "Iteration 103, loss = 0.02679357\n",
      "Iteration 104, loss = 0.02668784\n",
      "Iteration 105, loss = 0.02656488\n",
      "Iteration 106, loss = 0.02644658\n",
      "Iteration 107, loss = 0.02656251\n",
      "Iteration 108, loss = 0.02632166\n",
      "Iteration 109, loss = 0.02620435\n",
      "Iteration 110, loss = 0.02623777\n",
      "Iteration 111, loss = 0.02597423\n",
      "Iteration 112, loss = 0.02612747\n",
      "Iteration 113, loss = 0.02595742\n",
      "Iteration 114, loss = 0.02567986\n",
      "Iteration 115, loss = 0.02581642\n",
      "Iteration 116, loss = 0.02538980\n",
      "Iteration 117, loss = 0.02557753\n",
      "Iteration 118, loss = 0.02550077\n",
      "Iteration 119, loss = 0.02542999\n",
      "Iteration 120, loss = 0.02539850\n",
      "Iteration 121, loss = 0.02507540\n",
      "Iteration 122, loss = 0.02520507\n",
      "Iteration 123, loss = 0.02507708\n",
      "Iteration 124, loss = 0.02504652\n",
      "Iteration 125, loss = 0.02477329\n",
      "Iteration 126, loss = 0.02479239\n",
      "Iteration 127, loss = 0.02452888\n",
      "Iteration 128, loss = 0.02446076\n",
      "Iteration 129, loss = 0.02443378\n",
      "Iteration 130, loss = 0.02448224\n",
      "Iteration 131, loss = 0.02423054\n",
      "Iteration 132, loss = 0.02423577\n",
      "Iteration 133, loss = 0.02415584\n",
      "Iteration 134, loss = 0.02403691\n",
      "Iteration 135, loss = 0.02413553\n",
      "Iteration 136, loss = 0.02392753\n",
      "Iteration 137, loss = 0.02354551\n",
      "Iteration 138, loss = 0.02365656\n",
      "Iteration 139, loss = 0.02350479\n",
      "Iteration 140, loss = 0.02351230\n",
      "Iteration 141, loss = 0.02335263\n",
      "Iteration 142, loss = 0.02324096\n",
      "Iteration 143, loss = 0.02336560\n",
      "Iteration 144, loss = 0.02341230\n",
      "Iteration 145, loss = 0.02298931\n",
      "Iteration 146, loss = 0.02301817\n",
      "Iteration 147, loss = 0.02286861\n",
      "Iteration 148, loss = 0.02274431\n",
      "Iteration 149, loss = 0.02254443\n",
      "Iteration 150, loss = 0.02271085\n",
      "Iteration 151, loss = 0.02266417\n",
      "Iteration 152, loss = 0.02271446\n",
      "Iteration 153, loss = 0.02248768\n",
      "Iteration 154, loss = 0.02236540\n",
      "Iteration 155, loss = 0.02243306\n",
      "Iteration 156, loss = 0.02238457\n",
      "Iteration 157, loss = 0.02218465\n",
      "Iteration 158, loss = 0.02186706\n",
      "Iteration 159, loss = 0.02222095\n",
      "Iteration 160, loss = 0.02180337\n",
      "Iteration 161, loss = 0.02183789\n",
      "Iteration 162, loss = 0.02172753\n",
      "Iteration 163, loss = 0.02191090\n",
      "Iteration 164, loss = 0.02159950\n",
      "Iteration 165, loss = 0.02151567\n",
      "Iteration 166, loss = 0.02152674\n",
      "Iteration 167, loss = 0.02144396\n",
      "Iteration 168, loss = 0.02145606\n",
      "Iteration 169, loss = 0.02135317\n",
      "Iteration 170, loss = 0.02131136\n",
      "Iteration 171, loss = 0.02135001\n",
      "Iteration 172, loss = 0.02130843\n",
      "Iteration 173, loss = 0.02092768\n",
      "Iteration 174, loss = 0.02117751\n",
      "Iteration 175, loss = 0.02077267\n",
      "Iteration 176, loss = 0.02088539\n",
      "Iteration 177, loss = 0.02096867\n",
      "Iteration 178, loss = 0.02065403\n",
      "Iteration 179, loss = 0.02065225\n",
      "Iteration 180, loss = 0.02079423\n",
      "Iteration 181, loss = 0.02064899\n",
      "Iteration 182, loss = 0.02068330\n",
      "Iteration 183, loss = 0.02067131\n",
      "Iteration 184, loss = 0.02052882\n",
      "Iteration 185, loss = 0.02041333\n",
      "Iteration 186, loss = 0.02033087\n",
      "Iteration 187, loss = 0.02035559\n",
      "Iteration 188, loss = 0.01997413\n",
      "Iteration 189, loss = 0.02049686\n",
      "Iteration 190, loss = 0.02028232\n",
      "Iteration 191, loss = 0.01995826\n",
      "Iteration 192, loss = 0.02009848\n",
      "Iteration 193, loss = 0.02012938\n",
      "Iteration 194, loss = 0.02004612\n",
      "Iteration 195, loss = 0.02000434\n",
      "Iteration 196, loss = 0.01985707\n",
      "Iteration 197, loss = 0.01988359\n",
      "Iteration 198, loss = 0.01987073\n",
      "Iteration 199, loss = 0.01992002\n",
      "Iteration 200, loss = 0.01967209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\harik\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLPClassifier(hidden_layer_sizes=(100, 100, 100), random_state=21, solver='sgd',\n",
       "              verbose=10)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC \n",
    "from sklearn.naive_bayes import BernoulliNB \n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "# Train ADABOOST CLASSIFIER\n",
    "ADA_Classifier=AdaBoostClassifier()\n",
    "ADA_Classifier.fit(X_final_train,y_train)\n",
    "# Train KNeighborsClassifier Model\n",
    "KNN_Classifier = KNeighborsClassifier(n_jobs=-1)\n",
    "KNN_Classifier.fit(X_final_train, y_train)\n",
    "\n",
    "# Train LogisticRegression Model\n",
    "LGR_Classifier = LogisticRegression(C=0.01,random_state=42)\n",
    "LGR_Classifier.fit(X_final_train, y_train)\n",
    "\n",
    "# Train Gaussian Naive Baye Model\n",
    "BNB_Classifier = BernoulliNB()\n",
    "BNB_Classifier.fit(X_final_train, y_train)\n",
    "            \n",
    "# Train Decision Tree Model\n",
    "DTC_Classifier = tree.DecisionTreeClassifier(criterion='entropy', random_state=42,max_depth=10)\n",
    "DTC_Classifier.fit(X_final_train, y_train)\n",
    "            \n",
    "# Train SVM classifier\n",
    "SVC_Classifier = SVC(C=1,gamma='scale',kernel='rbf')\n",
    "SVC_Classifier.fit(X_final_train, y_train)\n",
    "# Train MLP Classifier\n",
    "MLP_Classifier = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=200, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10, random_state=21)\n",
    "MLP_Classifier.fit(X_final_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of train models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Accuracy:\n",
      " 0.9880053662292714\n",
      "\n",
      "Confusion matrix:\n",
      " [[58221   409]\n",
      " [ 1102 66241]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     58630\n",
      "           1       0.99      0.98      0.99     67343\n",
      "\n",
      "    accuracy                           0.99    125973\n",
      "   macro avg       0.99      0.99      0.99    125973\n",
      "weighted avg       0.99      0.99      0.99    125973\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8912465369563319\n",
      "\n",
      "Confusion matrix:\n",
      " [[50365  8265]\n",
      " [ 5435 61908]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88     58630\n",
      "           1       0.88      0.92      0.90     67343\n",
      "\n",
      "    accuracy                           0.89    125973\n",
      "   macro avg       0.89      0.89      0.89    125973\n",
      "weighted avg       0.89      0.89      0.89    125973\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9988807125336382\n",
      "\n",
      "Confusion matrix:\n",
      " [[58554    76]\n",
      " [   65 67278]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     58630\n",
      "           1       1.00      1.00      1.00     67343\n",
      "\n",
      "    accuracy                           1.00    125973\n",
      "   macro avg       1.00      1.00      1.00    125973\n",
      "weighted avg       1.00      1.00      1.00    125973\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9975947226786692\n",
      "\n",
      "Confusion matrix:\n",
      " [[58536    94]\n",
      " [  209 67134]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     58630\n",
      "           1       1.00      1.00      1.00     67343\n",
      "\n",
      "    accuracy                           1.00    125973\n",
      "   macro avg       1.00      1.00      1.00    125973\n",
      "weighted avg       1.00      1.00      1.00    125973\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy:\n",
      " 0.95845141419193\n",
      "\n",
      "Confusion matrix:\n",
      " [[55804  2826]\n",
      " [ 2408 64935]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96     58630\n",
      "           1       0.96      0.96      0.96     67343\n",
      "\n",
      "    accuracy                           0.96    125973\n",
      "   macro avg       0.96      0.96      0.96    125973\n",
      "weighted avg       0.96      0.96      0.96    125973\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9871242250323482\n",
      "\n",
      "Confusion matrix:\n",
      " [[57925   705]\n",
      " [  917 66426]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     58630\n",
      "           1       0.99      0.99      0.99     67343\n",
      "\n",
      "    accuracy                           0.99    125973\n",
      "   macro avg       0.99      0.99      0.99    125973\n",
      "weighted avg       0.99      0.99      0.99    125973\n",
      "\n",
      "\n",
      "\n",
      "Model Accuracy:\n",
      " 0.9940939725179205\n",
      "\n",
      "Confusion matrix:\n",
      " [[58391   239]\n",
      " [  505 66838]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99     58630\n",
      "           1       1.00      0.99      0.99     67343\n",
      "\n",
      "    accuracy                           0.99    125973\n",
      "   macro avg       0.99      0.99      0.99    125973\n",
      "weighted avg       0.99      0.99      0.99    125973\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "models = []\n",
    "models.append(('SVM Classifier', SVC_Classifier))\n",
    "models.append(('Naive Baye Classifier', BNB_Classifier))\n",
    "models.append(('Decision Tree Classifier', DTC_Classifier))\n",
    "models.append(('KNeighborsClassifier', KNN_Classifier))\n",
    "models.append(('LogisticRegression', LGR_Classifier))\n",
    "models.append(('AdaboostClassifier', ADA_Classifier))\n",
    "models.append((\"MLPClassifier\",MLP_Classifier))\n",
    "\n",
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(y_train, v.predict(X_final_train))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_train, v.predict(X_final_train))\n",
    "    classification = metrics.classification_report(y_train, v.predict(X_final_train))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation of test models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================== SVC(C=1) Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.805624556422995\n",
      "\n",
      "Confusion matrix:\n",
      " [[8765 4068]\n",
      " [ 314 9397]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.68      0.80     12833\n",
      "           1       0.70      0.97      0.81      9711\n",
      "\n",
      "    accuracy                           0.81     22544\n",
      "   macro avg       0.83      0.83      0.81     22544\n",
      "weighted avg       0.85      0.81      0.80     22544\n",
      "\n",
      "\n",
      "\n",
      "============================== BernoulliNB() Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7834013484740951\n",
      "\n",
      "Confusion matrix:\n",
      " [[8446 4387]\n",
      " [ 496 9215]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.66      0.78     12833\n",
      "           1       0.68      0.95      0.79      9711\n",
      "\n",
      "    accuracy                           0.78     22544\n",
      "   macro avg       0.81      0.80      0.78     22544\n",
      "weighted avg       0.83      0.78      0.78     22544\n",
      "\n",
      "\n",
      "\n",
      "============================== DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=42) Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.837473385379702\n",
      "\n",
      "Confusion matrix:\n",
      " [[10919  1914]\n",
      " [ 1750  7961]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.85      0.86     12833\n",
      "           1       0.81      0.82      0.81      9711\n",
      "\n",
      "    accuracy                           0.84     22544\n",
      "   macro avg       0.83      0.84      0.83     22544\n",
      "weighted avg       0.84      0.84      0.84     22544\n",
      "\n",
      "\n",
      "\n",
      "============================== KNeighborsClassifier(n_jobs=-1) Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.7747072391767211\n",
      "\n",
      "Confusion matrix:\n",
      " [[8014 4819]\n",
      " [ 260 9451]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.62      0.76     12833\n",
      "           1       0.66      0.97      0.79      9711\n",
      "\n",
      "    accuracy                           0.77     22544\n",
      "   macro avg       0.82      0.80      0.77     22544\n",
      "weighted avg       0.84      0.77      0.77     22544\n",
      "\n",
      "\n",
      "\n",
      "============================== LogisticRegression(C=0.01, random_state=42) Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.819153655074521\n",
      "\n",
      "Confusion matrix:\n",
      " [[9098 3735]\n",
      " [ 342 9369]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.71      0.82     12833\n",
      "           1       0.71      0.96      0.82      9711\n",
      "\n",
      "    accuracy                           0.82     22544\n",
      "   macro avg       0.84      0.84      0.82     22544\n",
      "weighted avg       0.86      0.82      0.82     22544\n",
      "\n",
      "\n",
      "\n",
      "============================== AdaBoostClassifier() Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8190649396735273\n",
      "\n",
      "Confusion matrix:\n",
      " [[10163  2670]\n",
      " [ 1409  8302]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.79      0.83     12833\n",
      "           1       0.76      0.85      0.80      9711\n",
      "\n",
      "    accuracy                           0.82     22544\n",
      "   macro avg       0.82      0.82      0.82     22544\n",
      "weighted avg       0.83      0.82      0.82     22544\n",
      "\n",
      "\n",
      "\n",
      "============================== MLPClassifier(hidden_layer_sizes=(100, 100, 100), random_state=21, solver='sgd',\n",
      "              verbose=10) Model Test Results ==============================\n",
      "\n",
      "Model Accuracy:\n",
      " 0.8105482611781405\n",
      "\n",
      "Confusion matrix:\n",
      " [[8949 3884]\n",
      " [ 387 9324]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.70      0.81     12833\n",
      "           1       0.71      0.96      0.81      9711\n",
      "\n",
      "    accuracy                           0.81     22544\n",
      "   macro avg       0.83      0.83      0.81     22544\n",
      "weighted avg       0.85      0.81      0.81     22544\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, v in models:\n",
    "    accuracy = metrics.accuracy_score(y_test, v.predict(X_final_test))\n",
    "    confusion_matrix = metrics.confusion_matrix(y_test, v.predict(X_final_test))\n",
    "    classification = metrics.classification_report(y_test, v.predict(X_final_test))\n",
    "    print()\n",
    "    print('============================== {} Model Test Results =============================='.format(v))\n",
    "    print()\n",
    "    print (\"Model Accuracy:\" \"\\n\", accuracy)\n",
    "    print()\n",
    "    print(\"Confusion matrix:\" \"\\n\", confusion_matrix)\n",
    "    print()\n",
    "    print(\"Classification report:\" \"\\n\", classification) \n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
